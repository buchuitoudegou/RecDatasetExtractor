# 科研实训进度报告

```
姓名：刘俊峰
学号：16340150
```



## 实训课题
将普通人像通过GAN转化成卡通人像。

## 需要解决的问题
1. **抽象，简化**。动画图片具有简化的特点，现实图片中的细节在动画中会被去除，如：人的脸部器官的简化、物体纹理的简化
2. **色彩**。卡通人像的色彩相较于真实的人像更加平滑，在阴影的处理上更加简单。
3. **形状**。卡通人像的脸部处理和真实的人像的区别在于，卡通人像的脸部更加简化，但是也和风格相关（有的和现实比较相近，有的简化的比较严重）

## 采取的解决方案

### 1. cycleGAN
cycleGAN是从上学期开始接触的模型。和普通的GAN的区别在于，它有两个相反的生成器，和两个判断不同风格的判别器。因此，它的loss也由以下几个部分组成：两个生成器的重构loss，两个生成器的交叉loss，两个判别器的loss。

使用了Vangogh2photo数据集进行测试
|lr|epoch|cyc（交叉loss的参数）|lid（判别器loss参数）|gloss|
|:-----:|:-----:|:-----:|:-----:|
|0.0002|100|10.0|5.0|0.5157|
|0.0002|200|10.0|5.0|0.3272|
|0.0001|100|10.0|5.0|0.4277|
|0.00001|100|10.0|5.0|0.6002|

cycleGAN的模型是由我自己在学习了pytorch之后实现的，大部分变量都是写死的，而且由于是第一次编写神经网络模型，因此前期一直状况不断。后来在叶林彬师兄的帮助下，并找了相关的cycleGAN的实现，才成功进行训练。虽然gloss的值和其他仓库的实现效果相差不大，但是生成出来的图片效果却差强人意，并不能达到预期的要求。

总结cycleGAN在模型上的缺点如下：
cycleGAN在风格转换上不能准确地识别出图片的语义部分，并进行对应的风格转换。即风格转换部分完全由模型通过训练习得，有时候在训练集不同的情况下，会造成要转换的部分转换成了奇怪的颜色。（在google cartoon dataset和celebA训练集上出现的状况）

另外，在训练的过程中发现，cycleGAN需要占用很多的资源（需要占用12GiB的显存），很难找到这样优质的GPU服务器资源。

### 2. CartoonGAN
CartoonGAN是2018CVPR提出的动画风格化模型，可以将真实场景转换成动画场景。这可以说是完全符合我们的要求。相比cycleGAN，CartoonGAN加入了语义信息的处理，即用VGG模型提取图片的特征，并用这类特征来进行风格化转换。这样，在保证了语义信息完整并且相互对应的情况下，风格化转换更加准确，需要的训练数据也比cycleGAN要少。同时，由于只有一个生成器，它占用的训练资源也比较少。

损失函数定义：
1.	语义特征损失。要生成真实照片对应的动画图片，生成的图片内容必须和原来的图片一致。
2.	卡通特征损失。即卡通图片的抽象、简化、色彩等特征。这一部分和普通的GAN损失定义基本一致。

尽管这个模型比较适合这个课题，但是在训练过程中也发现了不少问题。

**训练集**。不同的训练集在训练的时候，CartoonGAN的表现也不尽如人意。首先试验的是CUHK的人脸和Google cartoon dataset，由于风格的巨大差距，风格化出来图像有一定程度的扭曲，即五官没有完全对齐。在提高训练轮数和修改学习率等参数之后依然没有办法训练出完美的图片。但是在getchu和face_umd、anime和vgg_face等训练集上的表现都还不错。

**脸型的形变**。这一部分实际上是论文没有实现的。它做的主要部分就是色彩的变化，虽然输出的图片在色彩上和动漫图像比较相似（也要看数据集以及训练参数的调整）。

### 3. 编码器-解码器模型
编码-解码模型在解决脸型的形变上比前面的两个要优秀，最近接触到的有xgan和MUNIT模型。MUNIT模型用编码器提取了两种图片的特征后编码成一个向量，同时，编码器也会提取这个图片的风格化特征，也编码成一个向量。最后，将特征向量和风格向量重构出一个新的图片。

这种模型面临的困难就是编码。从现在接触过的模型看来，提取语义特征并编码都不是非常完美。拿xgan举例，在提取人脸的语义特征之后，结合卡通风格生成新图片的时候，丢失了大量真实人像的信息，考虑到要转换的风格，有些特征是不能丢弃的。

但是，由于时间关系，编码器-解码器类型的模型还没有完整完成训练（MUNIT还在训练中，中间生成的效果图不是很理想，需要继续调整）

## 总结

